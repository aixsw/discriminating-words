{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correr_Magic_Loop(self, npClassifier, npDictHyperParams, X_train, Y_train, nbrCv):\n",
    "\n",
    "        npResultados = np.array([])\n",
    "        for i, classifier in enumerate(npClassifier):\n",
    "            dictHyperParams = npDictHyperParams[i]\n",
    "\n",
    "            grid_search = GridSearchCV(classifier,\n",
    "                                       dictHyperParams,\n",
    "                                       scoring='f1',\n",
    "                                       cv=nbrCv,\n",
    "                                       n_jobs=-1,\n",
    "                                       verbose=3\n",
    "                                       )\n",
    "            grid_search.fit(X_train, Y_train)\n",
    "            npResultados = np.append(npResultados, grid_search)\n",
    "\n",
    "            # de los valores posibles que pusimos en el grid, cuáles fueron los mejores\n",
    "            print('grid_search.best_params_: ', grid_search.best_params_)\n",
    "\n",
    "            # mejor score asociado a los modelos generados con los diferentes hiperparametros\n",
    "            # corresponde al promedio de los scores generados con los cv\n",
    "            print('grid_search.best_score_: ', grid_search.best_score_)\n",
    "\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "        return best_model, npResultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prep_Modelos(npModelos):\n",
    "\n",
    "    npArrayModelos = np.array([])\n",
    "    for strModelo in npModelos:\n",
    "\n",
    "        if strModelo == 'DECTREE':\n",
    "            classifier = tree.DecisionTreeClassifier()\n",
    "        if strModelo == 'RANDOMF':\n",
    "            classifier = RandomForestClassifier()\n",
    "        if strModelo == 'XGBOOST':\n",
    "            classifier = GradientBoostingClassifier()\n",
    "\n",
    "        npArrayModelos = np.append(npArrayModelos, classifier)\n",
    "\n",
    "    return npArrayModelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrización para Árboles\n",
    "dictHyperParams = {'max_depth': [4],  # [4,7]\n",
    "                   'min_samples_split': [4],  # [4,16]\n",
    "                   'min_samples_leaf': [3],  # [3,7]\n",
    "                   'max_features': ['sqrt']  # ['sqrt','log2']\n",
    "                   }\n",
    "npDictHiperParam = np.append(npDictHiperParam, dictHyperParams)\n",
    "\n",
    "# Parametrización para Bosques\n",
    "dictHyperParams = {'n_estimators': [25],  # Se redujo a 50\n",
    "                   'max_depth': [4],  # [4,7]\n",
    "                   'max_features': ['sqrt'],  # ['sqrt','log2']\n",
    "                   'min_samples_split': [4],  # [4,16]\n",
    "                   'min_samples_leaf': [3]  # [3,7]\n",
    "                   }\n",
    "npDictHiperParam = np.append(npDictHiperParam, dictHyperParams)\n",
    "\n",
    "# Parametrización para XGBoost\n",
    "dictHyperParams = {'learning_rate': [0.25, 0.75],\n",
    "                   'n_estimators': [25],  # Se redujo a 50\n",
    "                   'min_samples_split': [4],  # [4,16]\n",
    "                   'min_samples_leaf': [3],  # [3,7]\n",
    "                   'max_depth': [5],  # [4,7]\n",
    "                   'max_features': ['sqrt']\n",
    "                   }\n",
    "npDictHiperParam = np.append(npDictHiperParam, dictHyperParams)\n",
    "\n",
    "# Se crean los modelos de clasificaión que se emplearán (en el mismo orden que los diccionarios)\n",
    "npNombreModelos = np.array([])\n",
    "npNombreModelos = np.append(npNombreModelos, 'DECTREE')\n",
    "npNombreModelos = np.append(npNombreModelos, 'RANDOMF')\n",
    "npNombreModelos = np.append(npNombreModelos, 'XGBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Sección del dataset a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrModelos = Prep_Modelos(npNombreModelos)\n",
    "\n",
    "# #Se corre el magic loop para realizar las predicciones con los parámetros previamente establecidos\n",
    "npGridSearchCv = Correr_Magic_Loop(arrModelos,\n",
    "                                    npDictHiperParam,\n",
    "                                    X_train,\n",
    "                                    Y_train,\n",
    "                                    5)\n",
    "\n",
    "npArrBestScores = np.array([])\n",
    "npArrBestParams = np.array([])\n",
    "\n",
    "# Barremos el arreglo de GridSearchCV´s para sacar los mejores scores y parámetros\n",
    "for grid in npGridSearchCv:\n",
    "    npArrBestScores = np.append(npArrBestScores, grid.best_score_)\n",
    "    npArrBestParams = np.append(npArrBestParams, grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el índice del mejor score\n",
    "nbrIndiceGanador = np.argmax(npArrBestScores, axis=0)\n",
    "\n",
    "# Mostramos el modelo, parámetros y score ganador\n",
    "# print(\"Modelo ganador: \\n\", arrModelos[nbrIndiceGanador])\n",
    "# print(\"Score del modelo ganador: \\n\", npArrBestScores[nbrIndiceGanador])\n",
    "# print(\"Parametros del modelo ganador: \\n\", npArrBestParams[nbrIndiceGanador])\n",
    "\n",
    "# Se instancia el modelo ganador\n",
    "# self.ModeloGanadorMagicLoop = objEda.InstanciarModeloDinamico(npNombreModelos, nbrIndiceGanador, npArrBestParams[nbrIndiceGanador])\n",
    "ModeloGanadorMagicLoop = objEda.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
